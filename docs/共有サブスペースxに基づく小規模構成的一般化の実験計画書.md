# 実験計画書：共有サブスペースXに基づく小規模構成的一般化の検証

## 0. 要旨（アブストラクト）
本計画は、表現空間にタスク横断で再利用可能な**共有サブスペースX**を形成させる軽量手法（サブスペース共有正則化＋疎オートエンコーダ補助）により、
(1) 未見合成への構成的一般化、(2) few-shot適応、(3) 学習時間短縮が同時に改善されることを、単一GPU・ミニ実装で検証する。8×8グリッドの合成タスクを用い、ベースラインと比較する。

---

## 1. 背景と問題意識
- 現行の生成AIは大規模事前学習により高性能だが、**構成的一般化**や**データ/時間効率**に課題が残る。
- 人間の推論は「**計算（ダイナミクス）と記憶**」が不可分で、複数課題の**共通部分（抽象）**をビルディングブロックとして再利用している可能性がある。
- 我々の作業仮説：モデル表現に**共有サブスペースX**を明示的に持たせ、その再利用を促すと、少ない追加学習で新規合成タスクに適応できる。

---

## 2. 目的（検証したい主張）
1. **共有サブスペースX形成**を促すだけの軽量な学習目標で、未見合成に対する**ゼロショット/少データ適応**が改善する。
2. 上記の効果は、**学習時間（到達ステップ/壁時計時間）**の観点でも有意。
3. 表現解析（CKA/Grassmann距離・疎特徴の可視化）により、**Xの存在と再利用**を定量・定性に確認できる。

---

## 3. 実験デザインの概要
- **データ**：8×8×C（C=4色程度）のグリッドタスク。原子操作（プリミティブ）を合成して入出力を生成。
  - 原子操作例：`ROT90`, `FLIP_H`, `COLOR_SWAP(a→b)`, `DRAW_BORDER(c)`, `FILL_COMPONENT(c)`, `SHIFT(dx,dy)`。
  - 学習：合成長1–2、テスト：**未見**の合成長3。
  - 各サンプルに使用プリミティブの**マルチホット**ラベルを付与。
- **モデル**：小型TransformerまたはGRUエンコーダ（2–4層, d=128）→ボトルネック表現h→デコーダ（出力グリッド回帰）。
  - 補助ヘッド：プリミティブ多ラベル分類。
  - **疎AE**：h→z（疎）→ĥ の再構成で“部品化”。
- **鍵となる損失**：
  - **サブスペース共有正則化**：タスク/組成ごとの表現行列の上位k主成分から射影行列を作り、群平均との二乗距離を最小化。
  - **疎AE補助**（L1による疎性＋再構成MSE）。
  - 追加：タスク損失（出力グリッドCE/IoU系）＋プリミティブ多ラベルBCE。

---

## 4. 仮説と評価指標
- **H1（構成的一般化）**：提案法はB0（ベースライン）より、未見合成（長3）で**IoU/Acc**が有意に高い。
- **H2（少データ適応）**：未見合成へのfew-shot適応で、**サンプル数–性能**曲線・**到達ステップ**が優位。
- **H3（学習時間効率）**：val-IoU到達までの**学習ステップ/時間**を短縮。
- **H4（表現の共有）**：タスク間の**CKA/Grassmann距離**が小さく、共有度が高い。疎特徴zがプリミティブと有意に対応。

**主要指標**：
- 構成的一般化：未見合成のIoU/Acc（ゼロショット／few-shot後）。
- 適応効率：到達ステップ、到達時間、必要サンプル数。
- 共有度：CKA（層×タスク）、Grassmann距離（上位k次元）、線形プローブ転移精度。
- 解釈：zユニット活性とプリミティブ出現の相関、可視化例。

---

## 5. ベースラインとアブレーション
- **B0**：標準学習（共有正則化・疎AEなし）。
- **B1**：補助のみ（疎AE＋プリミティブ予測、共有正則化なし）。
- **B2**：共有のみ（共有正則化、疎AEなし）。
- **B3**：疎AEの**非疎**（L1=0）。
- **B4**：few-shotで**Adapter/LoRAなし**の全層微調整。
- **B5**：**RNN vs Transformer**（再帰の影響）。
- **B6**：サブスペース次元kのスイープ（8/16/32）。

---

## 6. 手順（プロトコル）
1. **データ生成**：オンザフライ生成（学習5万/検証5千/テスト5千）。
2. **事前学習**：合成1–2で学習。損失 \(\mathcal{L}=\mathcal{L}_{task}+\alpha\mathcal{L}_{share}+\beta\mathcal{L}_{sae}+\gamma\mathcal{L}_{prim}\)。初期設定：\(\alpha=0.1, \beta=0.1, \gamma=0.5\)。
3. **ゼロショット評価**：未見合成（長3）で性能測定。
4. **few-shot適応**：各未見合成に対し5–20例で**LoRA/Adapterをボトルネック近傍に限定**し微調整（≤500 step）。
5. **学習時間記録**：同一GPUで学習曲線（step vs val-IoU）と壁時計時間をログ。
6. **表現解析**：
   - タスク間CKA/Grassmann距離（層別）。
   - 線形プローブ転移（Aで学んだプリミティブ検出器をBへ適用）。
   - SAEのzとプリミティブの相関・活性ヒートマップ。

---

## 7. 実装上の簡素化と安定化策
- **PCA**：`torch.pca_lowrank`で小規模バッチから上位k次元。平均射影は**detach**、1–Nステップごと更新。
- **グループ分け**：同一プリミティブマルチホットを1グループ（バッチ内に最低64サンプル以上を目安）。
- **疎化**：L1はウォームアップで増加。過疎/過密を監視しλを自動調整（目標平均活性率）。
- **過度共有の回避**：\(\alpha\)を0.05–0.2でスイープ。早期停止を併用。

---

## 8. 計算資源とタイムライン
- **資源**：単一GPU（T4/3090/V100想定）、RAM 16GB程度。
- **所要**：学習2–4時間、適応各数分〜十数分（環境依存）。
- **タイムライン**：
  - Week 1：データ生成・ベースライン実装、初期学習。
  - Week 2：共有正則化・疎AE追加、ゼロショット評価。
  - Week 3：few-shot適応、表現解析、アブレーション。
  - Week 4：図表作成・短報ドラフト。

---

## 9. 期待される結果と意義
- 共有サブスペース正則化＋疎AEにより、**未見合成のゼロショット/適応性能**が上昇し、**到達時間**が短縮。
- 解析により、**タスク間サブスペースの収束**と**疎特徴のプリミティブ対応**を確認。
- 小規模・汎用的手法として、**構成的一般化**と**学習効率**の改善に対するシンプルなベースラインを提供。

---

## 10. リスクと代替案
- **PCA不安定**：グループサイズ拡大、EMA平均、ランダム射影近似で代替。
- **表現崩壊**：\(\alpha\)を縮小、補助損失の重み調整、Dropout導入。
- **未見合成が易/難**：プリミティブ数・色数・連結成分制約で難易度調整。

---

## 11. 公開物と再現性
- コード（100–200行の最小版＋データ生成スクリプト）。
- ログとシード、ハイパラ表、チェックポイント。
- 図：学習曲線、ゼロショット/適応バー、CKA/Grassmannヒートマップ、疎特徴の可視化例。

---

## 12. 短報ドラフト構成（目安）
1. はじめに（背景と課題）
2. 提案手法の直観（共有サブスペースX）
3. セットアップ（データ・モデル・損失）
4. 結果（一般化・適応・時間、表現解析）
5. 関連研究との比較（簡潔に）
6. 限界と今後（ARC系への波及）
7. まとめ

---

## 付録A：損失の定式化（簡易）
- タスク損失：\(\mathcal{L}_{task}=\text{CE}(\hat{Y},Y)\) or 1−IoU。
- 共有正則化：グループtの中心化表現行列 \(H_t\) から \(U_t=\mathrm{PCA}_k(H_t)\)、\(P_t=U_tU_t^T\)。\(\bar P=\frac{1}{|T|}\sum_t P_t\)。
  \[\mathcal{L}_{share}=\frac{1}{|T|}\sum_t \|P_t-\bar P\|_F^2\]
- 疎AE：\(\mathcal{L}_{sae}=\|h-\hat h\|_2^2+\lambda\|z\|_1\)。
- プリミティブ補助：\(\mathcal{L}_{prim}=\text{BCEWithLogits}(\hat p, p)\)。
- 総損失：\(\mathcal{L}=\mathcal{L}_{task}+\alpha\mathcal{L}_{share}+\beta\mathcal{L}_{sae}+\gamma\mathcal{L}_{prim}\)。

---

## 付録B：few-shot適応の範囲
- LoRA/Adapterはボトルネック周辺（h周りの線形層）に限定。学習率小、step ≤ 500。
- 早期停止基準：検証IoUの改善停滞（patience 25–50 step）。

